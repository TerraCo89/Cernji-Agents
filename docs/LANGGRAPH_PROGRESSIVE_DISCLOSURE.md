# LangGraph Progressive Disclosure Pattern

**Speed up development with simple, self-contained LangGraph agents**

## The Problem with Monolithic LangGraph Agents

Traditional LangGraph development often leads to:
- âŒ One massive `graph.py` file (300+ lines)
- âŒ High context window consumption
- âŒ Slow iteration (edit one workflow, reload everything)
- âŒ Difficult testing (hard to isolate workflows)

## The Solution: Self-Contained Agent Files

Apply the progressive disclosure pattern from `/prime-agentic-systems`:

```
apps/resume-agent-langgraph/src/resume_agent/graphs/
â”œâ”€â”€ job_analyzer.py        # ~150 lines - Job analysis workflow
â”œâ”€â”€ resume_tailor.py       # ~200 lines - Resume customization
â”œâ”€â”€ cover_letter.py        # ~180 lines - Cover letter generation
â”œâ”€â”€ portfolio_finder.py    # ~160 lines - GitHub code search
â””â”€â”€ ats_scorer.py          # ~120 lines - ATS compatibility
```

Each file is a **complete, independent agent** with:
- Graph definition
- State schema
- Nodes
- Tools
- Routing logic

## Architecture: Multi-Agent Pattern

### 1. Self-Contained Graph Template

Each graph file (~150-200 lines):

```python
"""Job Analysis Agent - Analyze job postings and extract requirements."""

from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.tools import tool
from typing import TypedDict, Annotated, Optional
from langchain_core.messages import AIMessage, HumanMessage

# ==============================================================================
# State Schema
# ==============================================================================

class JobAnalyzerState(TypedDict, total=False):
    """State for job analysis workflow."""
    messages: Annotated[list, "Messages in conversation"]
    job_url: Optional[str]
    job_content: Optional[str]
    job_analysis: Optional[dict]
    cached: bool
    errors: list[str]

# ==============================================================================
# Tools (embedded in this file)
# ==============================================================================

@tool
def fetch_job_posting(url: str) -> str:
    """Fetch job posting content from URL."""
    # Implementation here
    pass

# ==============================================================================
# Nodes (embedded in this file)
# ==============================================================================

def check_cache_node(state: JobAnalyzerState) -> dict:
    """Check if job analysis is cached."""
    # Implementation
    return {"cached": False}

def fetch_job_node(state: JobAnalyzerState) -> dict:
    """Fetch job posting content."""
    # Implementation
    return {"job_content": "..."}

def analyze_job_node(state: JobAnalyzerState) -> dict:
    """Analyze job posting with LLM."""
    # Implementation
    return {"job_analysis": {...}}

# ==============================================================================
# Graph Construction
# ==============================================================================

def build_job_analyzer_graph():
    """Build job analysis agent graph.

    Flow: check_cache â†’ fetch_job â†’ analyze_job â†’ END
    """
    graph = StateGraph(JobAnalyzerState)

    # Add nodes
    graph.add_node("check_cache", check_cache_node)
    graph.add_node("fetch_job", fetch_job_node)
    graph.add_node("analyze_job", analyze_job_node)

    # Define flow
    graph.add_edge(START, "check_cache")
    graph.add_conditional_edges(
        "check_cache",
        lambda s: "fetch_job" if not s.get("cached") else END,
        {"fetch_job": "fetch_job", END: END}
    )
    graph.add_edge("fetch_job", "analyze_job")
    graph.add_edge("analyze_job", END)

    # Compile with checkpointing
    return graph.compile(checkpointer=MemorySaver())

# Export compiled graph
graph = build_job_analyzer_graph()
```

### 2. Expose Agents in langgraph.json

```json
{
  "$schema": "https://langgra.ph/schema.json",
  "dependencies": [".", "./src"],
  "graphs": {
    "job_analyzer": "./src/resume_agent/graphs/job_analyzer.py:graph",
    "resume_tailor": "./src/resume_agent/graphs/resume_tailor.py:graph",
    "cover_letter": "./src/resume_agent/graphs/cover_letter.py:graph",
    "portfolio_finder": "./src/resume_agent/graphs/portfolio_finder.py:graph",
    "ats_scorer": "./src/resume_agent/graphs/ats_scorer.py:graph"
  },
  "env": ".env"
}
```

### 3. Agent Chat UI - Agent Selection

The UI can now switch between specialized agents:

```typescript
// Agent selection component
const agents = [
  { id: 'job_analyzer', name: 'Job Analyzer', icon: 'ğŸ”' },
  { id: 'resume_tailor', name: 'Resume Tailor', icon: 'ğŸ“' },
  { id: 'cover_letter', name: 'Cover Letter', icon: 'âœ‰ï¸' },
  { id: 'portfolio_finder', name: 'Portfolio Finder', icon: 'ğŸ’¼' },
  { id: 'ats_scorer', name: 'ATS Scorer', icon: 'ğŸ“Š' }
];

// Create thread for specific agent
const threadId = await client.threads.create({
  metadata: { agent: selectedAgent }
});

// Stream from specific agent
const stream = client.runs.stream(
  threadId,
  selectedAgent, // Agent name from langgraph.json
  { input: { messages: [{ role: "human", content: message }] } }
);
```

## Benefits vs Monolithic Approach

| Aspect | Monolithic Graph | Progressive Disclosure |
|--------|------------------|------------------------|
| File Size | 300+ lines | 150-200 lines each |
| Context Window | HIGH (load everything) | LOW (load one agent) |
| Iteration Speed | Slow (reload all) | Fast (edit one file) |
| Testing | Complex (full graph) | Simple (isolated) |
| Collaboration | Merge conflicts | Independent files |
| Production Ready | âœ… Yes | âœ… Yes |

## Implementation Strategy

### Step 1: Extract Existing Workflows

You already have modular graphs! Just expose them:

**Current structure:**
```
src/resume_agent/graphs/
â”œâ”€â”€ job_analysis.py        âœ… Already exists!
â”œâ”€â”€ resume_tailor.py       âœ… Already exists!
â”œâ”€â”€ cover_letter.py        âœ… Already exists!
â””â”€â”€ conversation.py        âœ… Already exists!
```

**Action:** Update `langgraph.json` to expose each graph.

### Step 2: Ensure Self-Containment

Each graph file should be independently runnable:

```python
# At the bottom of each graph file, enable standalone testing:
if __name__ == "__main__":
    # Quick test
    graph = build_job_analyzer_graph()
    result = graph.invoke(
        {"job_url": "https://example.com/job"},
        config={"configurable": {"thread_id": "test-1"}}
    )
    print(result)
```

### Step 3: Update Agent Chat UI

Add agent selection to the UI:

```typescript
// components/agent-selector.tsx
export function AgentSelector() {
  const [selectedAgent, setSelectedAgent] = useState('job_analyzer');

  return (
    <select onChange={(e) => setSelectedAgent(e.target.value)}>
      <option value="job_analyzer">ğŸ” Job Analyzer</option>
      <option value="resume_tailor">ğŸ“ Resume Tailor</option>
      <option value="cover_letter">âœ‰ï¸ Cover Letter</option>
    </select>
  );
}
```

## Progressive Disclosure in Practice

### Scenario: Adding a New Agent

**Without Progressive Disclosure** (Monolithic):
1. Open massive `graph.py` (300+ lines)
2. Add new state fields (risk breaking existing)
3. Add new nodes (scroll through file)
4. Add new routing logic (complex conditionals)
5. Test entire graph (slow feedback)

**With Progressive Disclosure:**
1. Create new file: `linkedin_optimizer.py` (~150 lines)
2. Define isolated state schema
3. Write nodes in same file
4. Build graph
5. Add one line to `langgraph.json`
6. Test isolated graph (fast feedback)

**Time saved: 80%** ğŸš€

### Scenario: Debugging a Workflow

**Without Progressive Disclosure:**
```bash
# Load entire graph with all workflows
pytest tests/integration/test_all_workflows.py  # 5 minutes
```

**With Progressive Disclosure:**
```bash
# Test only the workflow you're debugging
pytest tests/integration/test_job_analyzer.py   # 30 seconds
```

## Best Practices

### 1. Keep Graphs Under 200 Lines

If a graph exceeds 200 lines, split it:

```python
# TOO BIG: job_application_complete.py (400 lines)

# BETTER: Split into focused agents
# - job_analyzer.py (150 lines)
# - resume_tailor.py (180 lines)
# - cover_letter.py (160 lines)
```

### 2. Embed Dependencies

Include tools and nodes in the same file (acceptable duplication):

```python
# âœ… Good: Self-contained
# graphs/job_analyzer.py contains:
# - State schema
# - Tools
# - Nodes
# - Graph definition

# âŒ Avoid: Excessive sharing
# - Shared tool files that couple graphs
# - Complex import hierarchies
```

### 3. Use Descriptive Agent Names

```json
{
  "graphs": {
    "job_analyzer": "...",           // âœ… Clear purpose
    "resume_tailor": "...",          // âœ… Clear purpose
    "agent1": "...",                 // âŒ Unclear
    "workflow": "..."                // âŒ Too generic
  }
}
```

### 4. Add Standalone Testing

Each graph should be testable independently:

```python
# Bottom of job_analyzer.py
if __name__ == "__main__":
    import sys
    graph = build_job_analyzer_graph()

    result = graph.invoke(
        {"job_url": sys.argv[1]},
        config={"configurable": {"thread_id": "cli-test"}}
    )

    print(result["job_analysis"])
```

Run with: `python -m resume_agent.graphs.job_analyzer https://example.com/job`

## Integration with Agent Chat UI

### Multi-Agent Architecture

```
User â†’ Agent Chat UI â†’ LangGraph Server (port 2024)
                            â†“
                    [Multiple Agents]
                    â”œâ”€â”€ job_analyzer
                    â”œâ”€â”€ resume_tailor
                    â”œâ”€â”€ cover_letter
                    â””â”€â”€ portfolio_finder
```

### Agent Selection Flow

1. **User selects agent** in UI dropdown
2. **UI creates thread** for that agent
3. **UI streams from specific graph** endpoint
4. **LangGraph server** loads only that graph
5. **Progressive disclosure** - minimal context consumption

### Code Example

```typescript
// lib/langgraph-client.ts
export async function createAgentThread(agentId: string) {
  const client = new Client({ apiUrl: LANGGRAPH_API_URL });

  // Create thread for specific agent
  const thread = await client.threads.create({
    metadata: {
      agent: agentId,
      created_at: new Date().toISOString()
    }
  });

  return thread.thread_id;
}

export async function streamAgentResponse(
  agentId: string,
  threadId: string,
  message: string
) {
  const client = new Client({ apiUrl: LANGGRAPH_API_URL });

  // Stream from specific agent graph
  const stream = client.runs.stream(
    threadId,
    agentId, // This is the key from langgraph.json
    {
      input: {
        messages: [{ role: "human", content: message }]
      }
    }
  );

  for await (const chunk of stream) {
    yield chunk;
  }
}
```

## Comparison: The 4 Approaches

Applied to LangGraph development:

### 1. MCP Server Wrapping CLI
**When:** External tools, multi-client support needed

```
Claude â†’ MCP â†’ CLI â†’ LangGraph API
```
- âŒ Context loss on every call
- âœ… Works with any MCP client

### 2. LangGraph CLI + Scripts
**When:** Need both programmatic and CLI access

```
Claude â†’ uv run script.py â†’ LangGraph HTTP API
```
- âœ… Direct control, caching possible
- âš ï¸ Subprocess overhead

### 3. Self-Contained Graph Files (RECOMMENDED)
**When:** Building agents for production

```
Claude â†’ Read graph file â†’ LangGraph Server exposes graph
```
- âœ… Progressive disclosure
- âœ… Fast iteration
- âœ… Production-ready
- âœ… Minimal context consumption

### 4. Skills (Claude Code)
**When:** Team collaboration, autonomous discovery

```
Claude (detects trigger) â†’ Reads SKILL.md â†’ Calls LangGraph API
```
- âœ… Git-shareable workflows
- âœ… Autonomous invocation
- âš ï¸ Claude Code specific

## Migration Checklist

Transform your LangGraph development:

- [ ] Audit existing `graph.py` size (>300 lines?)
- [ ] Identify distinct workflows (job analysis, resume tailoring, etc.)
- [ ] Extract each workflow to `graphs/{workflow}.py` (~150-200 lines each)
- [ ] Ensure each graph is self-contained (state, tools, nodes in same file)
- [ ] Update `langgraph.json` to expose each graph as separate agent
- [ ] Add standalone testing (`if __name__ == "__main__"`)
- [ ] Update Agent Chat UI to support agent selection
- [ ] Test each agent independently
- [ ] Deploy to LangGraph Cloud (all agents auto-discovered)

## Success Metrics

Your LangGraph development is optimized when:

- âœ… Each graph file is 100-200 lines
- âœ… Graphs are independently testable
- âœ… Adding new agents takes <30 minutes
- âœ… Context window consumption is minimal
- âœ… Team members can work on different agents without conflicts
- âœ… UI lets users switch between specialized agents
- âœ… LangGraph server auto-discovers all agents from `langgraph.json`

## Next Steps

1. **Review existing graphs** - You already have `job_analysis.py`, `resume_tailor.py`, etc.
2. **Update langgraph.json** - Expose each graph as a separate agent
3. **Test independently** - Verify each graph works in isolation
4. **Update Agent Chat UI** - Add agent selection dropdown
5. **Deploy** - LangGraph Cloud auto-deploys all agents

## Resources

- **Current Implementation:** `apps/resume-agent-langgraph/src/resume_agent/graphs/`
- **LangGraph Multi-Agent:** https://langchain-ai.github.io/langgraph/how-tos/branching/
- **Agent Chat UI:** `apps/agent-chat-ui/`
- **Prime Agentic Systems:** `.claude/commands/prime-agentic-systems.md`

---

**Remember:** The goal is NOT to build the most sophisticated multi-agent system. The goal is to build simple, specialized agents that are fast to iterate on and maintain full conversational context.
