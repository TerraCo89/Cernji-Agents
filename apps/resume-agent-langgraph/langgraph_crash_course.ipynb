{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Crash Course: From State Machines to Legal AI Agents\n",
    "\n",
    "**Interview Prep for LegalOn Technologies**  \n",
    "*Building on your game dev state machine & orchestrator experience*\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python314\\python.exe: No module named uv\n"
     ]
    }
   ],
   "source": [
    "uv sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langchain-anthropic\n",
      "  Downloading langchain_anthropic-1.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-1.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic>=2.7.4 (from langgraph)\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.6.0-cp314-cp314-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.11.0-cp314-cp314-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph)\n",
      "  Downloading orjson-3.11.3-cp314-cp314-win_amd64.whl.metadata (43 kB)\n",
      "Collecting anthropic<1.0.0,>=0.69.0 (from langchain-anthropic)\n",
      "  Downloading anthropic-0.71.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core)\n",
      "  Downloading langsmith-0.4.37-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\cernj\\appdata\\roaming\\python\\python314\\site-packages (from langchain-core) (25.0)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core)\n",
      "  Downloading pyyaml-6.0.3-cp314-cp314-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain-core)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from anthropic<1.0.0,>=0.69.0->langchain-anthropic)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic<1.0.0,>=0.69.0->langchain-anthropic)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting docstring-parser<1,>=0.15 (from anthropic<1.0.0,>=0.69.0->langchain-anthropic)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic<1.0.0,>=0.69.0->langchain-anthropic)\n",
      "  Downloading jiter-0.11.1-cp314-cp314-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from anthropic<1.0.0,>=0.69.0->langchain-anthropic)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.69.0->langchain-anthropic)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Downloading zstandard-0.25.0-cp314-cp314-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading pydantic_core-2.41.4-cp314-cp314-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cernj\\appdata\\roaming\\python\\python314\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.3)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langchain_anthropic-1.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langchain_core-1.0.0-py3-none-any.whl (467 kB)\n",
      "Downloading anthropic-0.71.0-py3-none-any.whl (355 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.11.1-cp314-cp314-win_amd64.whl (202 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.4.37-py3-none-any.whl (396 kB)\n",
      "Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp314-cp314-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 86.1 MB/s  0:00:00\n",
      "Downloading pyyaml-6.0.3-cp314-cp314-win_amd64.whl (156 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.11.3-cp314-cp314-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.11.0-cp314-cp314-win_amd64.whl (112 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.6.0-cp314-cp314-win_amd64.whl (32 kB)\n",
      "Downloading zstandard-0.25.0-cp314-cp314-win_amd64.whl (516 kB)\n",
      "Installing collected packages: zstandard, xxhash, urllib3, typing-extensions, tenacity, sniffio, pyyaml, python-dotenv, ormsgpack, orjson, jsonpointer, jiter, idna, h11, docstring-parser, distro, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, requests-toolbelt, pydantic, httpx, langsmith, langgraph-sdk, anthropic, langchain-core, langgraph-checkpoint, langchain-anthropic, langgraph-prebuilt, langgraph\n",
      "\n",
      "   -- -------------------------------------  2/35 [urllib3]\n",
      "   --- ------------------------------------  3/35 [typing-extensions]\n",
      "   ------ ---------------------------------  6/35 [pyyaml]\n",
      "   -------- -------------------------------  7/35 [python-dotenv]\n",
      "   -------------- ------------------------- 13/35 [h11]\n",
      "   ---------------- ----------------------- 14/35 [docstring-parser]\n",
      "   -------------------- ------------------- 18/35 [typing-inspection]\n",
      "   ------------------------ --------------- 21/35 [jsonpatch]\n",
      "   ------------------------- -------------- 22/35 [httpcore]\n",
      "   -------------------------- ------------- 23/35 [anyio]\n",
      "   --------------------------- ------------ 24/35 [requests-toolbelt]\n",
      "   ---------------------------- ----------- 25/35 [pydantic]\n",
      "   ---------------------------- ----------- 25/35 [pydantic]\n",
      "   ---------------------------- ----------- 25/35 [pydantic]\n",
      "   ---------------------------- ----------- 25/35 [pydantic]\n",
      "   ---------------------------- ----------- 25/35 [pydantic]\n",
      "   ----------------------------- ---------- 26/35 [httpx]\n",
      "   ------------------------------ --------- 27/35 [langsmith]\n",
      "   ------------------------------ --------- 27/35 [langsmith]\n",
      "   ------------------------------ --------- 27/35 [langsmith]\n",
      "   -------------------------------- ------- 28/35 [langgraph-sdk]\n",
      "   --------------------------------- ------ 29/35 [anthropic]\n",
      "   --------------------------------- ------ 29/35 [anthropic]\n",
      "   --------------------------------- ------ 29/35 [anthropic]\n",
      "   --------------------------------- ------ 29/35 [anthropic]\n",
      "   --------------------------------- ------ 29/35 [anthropic]\n",
      "   --------------------------------- ------ 29/35 [anthropic]\n",
      "   --------------------------------- ------ 29/35 [anthropic]\n",
      "   --------------------------------- ------ 29/35 [anthropic]\n",
      "   --------------------------------- ------ 29/35 [anthropic]\n",
      "   --------------------------------- ------ 29/35 [anthropic]\n",
      "   ---------------------------------- ----- 30/35 [langchain-core]\n",
      "   ---------------------------------- ----- 30/35 [langchain-core]\n",
      "   ---------------------------------- ----- 30/35 [langchain-core]\n",
      "   ---------------------------------- ----- 30/35 [langchain-core]\n",
      "   ---------------------------------- ----- 30/35 [langchain-core]\n",
      "   ---------------------------------- ----- 30/35 [langchain-core]\n",
      "   ----------------------------------- ---- 31/35 [langgraph-checkpoint]\n",
      "   ------------------------------------- -- 33/35 [langgraph-prebuilt]\n",
      "   -------------------------------------- - 34/35 [langgraph]\n",
      "   -------------------------------------- - 34/35 [langgraph]\n",
      "   ---------------------------------------- 35/35 [langgraph]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anthropic-0.71.0 anyio-4.11.0 certifi-2025.10.5 distro-1.9.0 docstring-parser-0.17.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.11.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-anthropic-1.0.0 langchain-core-1.0.0 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 langsmith-0.4.37 orjson-3.11.3 ormsgpack-1.11.0 pydantic-2.12.3 pydantic-core-2.41.4 python-dotenv-1.1.1 pyyaml-6.0.3 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.5.0 xxhash-3.6.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Run this first!\n",
    "%pip install langgraph langchain-anthropic langchain-core python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "# Make sure you have ANTHROPIC_API_KEY in your .env file\n",
    "# or set it here:\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concept 1: StateGraph Basics - Your Game State, but for Agents\n",
    "\n",
    "In game programming, you had:\n",
    "```python\n",
    "class NPCState:\n",
    "    position: Vector3\n",
    "    health: int\n",
    "    target: Enemy\n",
    "```\n",
    "\n",
    "LangGraph uses `TypedDict` for strongly-typed state that flows through the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cernj\\AppData\\Roaming\\Python\\Python314\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: hello langgraph\n",
      "Finalizing after 1 steps\n",
      "\n",
      "Final state:\n",
      "{'message': 'HELLO LANGGRAPH', 'steps_taken': 1, 'is_complete': True}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Define your state schema\n",
    "class AgentState(TypedDict):\n",
    "    message: str\n",
    "    steps_taken: int\n",
    "    is_complete: bool\n",
    "\n",
    "# Nodes are just functions that take state and return state updates\n",
    "def process_node(state: AgentState) -> dict:\n",
    "    print(f\"Processing: {state['message']}\")\n",
    "    return {\n",
    "        \"message\": state[\"message\"].upper(),\n",
    "        \"steps_taken\": state[\"steps_taken\"] + 1\n",
    "    }\n",
    "\n",
    "def finalize_node(state: AgentState) -> dict:\n",
    "    print(f\"Finalizing after {state['steps_taken']} steps\")\n",
    "    return {\"is_complete\": True}\n",
    "\n",
    "# Build the graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"process\", process_node)\n",
    "graph.add_node(\"finalize\", finalize_node)\n",
    "\n",
    "# Define flow: START -> process -> finalize -> END\n",
    "graph.add_edge(START, \"process\")\n",
    "graph.add_edge(\"process\", \"finalize\")\n",
    "graph.add_edge(\"finalize\", END)\n",
    "\n",
    "# Compile and run\n",
    "app = graph.compile()\n",
    "\n",
    "# Invoke with initial state\n",
    "result = app.invoke({\n",
    "    \"message\": \"hello langgraph\",\n",
    "    \"steps_taken\": 0,\n",
    "    \"is_complete\": False\n",
    "})\n",
    "\n",
    "print(\"\\nFinal state:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight**: \n",
    "- Nodes return **partial updates** (only changed fields)\n",
    "- LangGraph **automatically merges** them back into state\n",
    "- Like your game loop updating only changed properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concept 2: Conditional Edges - Animation State Transitions\n",
    "\n",
    "Remember animation state machines?\n",
    "```python\n",
    "if health < 20:\n",
    "    transition_to(\"flee\")\n",
    "elif enemy_in_range:\n",
    "    transition_to(\"attack\")\n",
    "```\n",
    "\n",
    "LangGraph uses **conditional edges** for dynamic routing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1\n",
      "Count: 2\n",
      "Count: 3\n",
      "Count: 4\n",
      "Count: 5\n",
      "\n",
      "Final count: 5\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class CounterState(TypedDict):\n",
    "    count: int\n",
    "    max_count: int\n",
    "\n",
    "def increment_node(state: CounterState) -> dict:\n",
    "    new_count = state[\"count\"] + 1\n",
    "    print(f\"Count: {new_count}\")\n",
    "    return {\"count\": new_count}\n",
    "\n",
    "# Conditional routing function (like your game state machine)\n",
    "def should_continue(state: CounterState) -> Literal[\"continue\", \"stop\"]:\n",
    "    if state[\"count\"] >= state[\"max_count\"]:\n",
    "        return \"stop\"\n",
    "    return \"continue\"\n",
    "\n",
    "# Build graph with conditional routing\n",
    "graph = StateGraph(CounterState)\n",
    "graph.add_node(\"increment\", increment_node)\n",
    "\n",
    "graph.add_edge(START, \"increment\")\n",
    "\n",
    "# Conditional edge: route based on state\n",
    "graph.add_conditional_edges(\n",
    "    \"increment\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"increment\",  # Loop back to self\n",
    "        \"stop\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "result = app.invoke({\"count\": 0, \"max_count\": 5})\n",
    "print(f\"\\nFinal count: {result['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight**: \n",
    "- Conditional edges enable **loops** (self-edges)\n",
    "- The routing function decides the next node\n",
    "- This is how agents decide to continue or finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concept 3: ReAct Pattern - The Classic Agent Loop\n",
    "\n",
    "This is the bread and butter of autonomous agents. Like your Claude Code orchestrator:\n",
    "1. **Think** (reason about what to do)\n",
    "2. **Act** (execute tool/action)\n",
    "3. **Observe** (get result)\n",
    "4. **Repeat** until done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  REASONING...\n",
      "   Decision: i need to break this down into two parts:\n",
      "\n",
      "1. first part: \"what is 2+2?\" - this is a simple calculation\n",
      "2. second part: \"then tell me what langgraph is\" - this requires looking up information\n",
      "\n",
      "let me start with the first action:\n",
      "\n",
      "calculate\n",
      "\n",
      "ðŸ”§ EXECUTING ACTION: i need to break this down into two parts:\n",
      "\n",
      "1. first part: \"what is 2+2?\" - this is a simple calculation\n",
      "2. second part: \"then tell me what langgraph is\" - this requires looking up information\n",
      "\n",
      "let me start with the first action:\n",
      "\n",
      "calculate\n",
      "   Result: [Calculation] 2 + 2 = 4\n",
      "\n",
      "ðŸ§  REASONING...\n",
      "   Decision: now i need to search for information about langgraph:\n",
      "\n",
      "search\n",
      "\n",
      "ðŸ”§ EXECUTING ACTION: now i need to search for information about langgraph:\n",
      "\n",
      "search\n",
      "   Result: [Search Result] LangGraph is a framework for building stateful LLM agents.\n",
      "\n",
      "ðŸ§  REASONING...\n",
      "   Decision: answer\n",
      "\n",
      "============================================================\n",
      "FINAL MESSAGES:\n",
      "  HumanMessage: What is 2+2? Then tell me what LangGraph is....\n",
      "  AIMessage: I need to break this down into two parts:\n",
      "\n",
      "1. First part: \"What is 2+2?\" - This is a simple calculat...\n",
      "  HumanMessage: Tool result: [Calculation] 2 + 2 = 4...\n",
      "  AIMessage: Now I need to search for information about LangGraph:\n",
      "\n",
      "search...\n",
      "  HumanMessage: Tool result: [Search Result] LangGraph is a framework for building stateful LLM agents....\n",
      "  AIMessage: answer...\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from typing import Annotated\n",
    "from operator import add\n",
    "\n",
    "# State with append-only messages (critical!)\n",
    "class ReActState(TypedDict):\n",
    "    messages: Annotated[list, add]  # 'add' means append, not replace\n",
    "    next_action: str\n",
    "\n",
    "# Initialize Claude\n",
    "llm = ChatAnthropic(model=\"claude-sonnet-4-5\", temperature=0)\n",
    "\n",
    "# Reasoning node: LLM decides what to do\n",
    "def reasoning_node(state: ReActState) -> dict:\n",
    "    print(\"\\nðŸ§  REASONING...\")\n",
    "    \n",
    "    # Add system prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=\"\"\"You are an AI assistant. Decide if you need to:\n",
    "        - 'search': Look up information\n",
    "        - 'calculate': Perform a calculation\n",
    "        - 'answer': Provide final answer\n",
    "        \n",
    "        Respond with ONLY the action name.\"\"\")\n",
    "    ] + state[\"messages\"]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    action = response.content.strip().lower()\n",
    "    \n",
    "    print(f\"   Decision: {action}\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"next_action\": action\n",
    "    }\n",
    "\n",
    "# Action node: Execute the decided action\n",
    "def action_node(state: ReActState) -> dict:\n",
    "    print(f\"\\nðŸ”§ EXECUTING ACTION: {state['next_action']}\")\n",
    "    \n",
    "    # Simulate tool execution\n",
    "    if \"search\" in state[\"next_action\"]:\n",
    "        result = \"[Search Result] LangGraph is a framework for building stateful LLM agents.\"\n",
    "    elif \"calculate\" in state[\"next_action\"]:\n",
    "        result = \"[Calculation] 2 + 2 = 4\"\n",
    "    else:\n",
    "        result = \"Action completed.\"\n",
    "    \n",
    "    print(f\"   Result: {result}\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=f\"Tool result: {result}\")]\n",
    "    }\n",
    "\n",
    "# Router: Decide if we're done or need another loop\n",
    "def should_continue(state: ReActState) -> Literal[\"action\", \"end\"]:\n",
    "    if \"answer\" in state[\"next_action\"]:\n",
    "        return \"end\"\n",
    "    return \"action\"\n",
    "\n",
    "# Build the ReAct graph\n",
    "graph = StateGraph(ReActState)\n",
    "graph.add_node(\"reasoning\", reasoning_node)\n",
    "graph.add_node(\"action\", action_node)\n",
    "\n",
    "graph.add_edge(START, \"reasoning\")\n",
    "graph.add_edge(\"action\", \"reasoning\")  # Loop back after action\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"reasoning\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"action\": \"action\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# Test it\n",
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is 2+2? Then tell me what LangGraph is.\")],\n",
    "    \"next_action\": \"\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL MESSAGES:\")\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"  {msg.__class__.__name__}: {msg.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insights**:\n",
    "- `Annotated[list, add]` makes messages **append-only** (like Redux)\n",
    "- The loop continues until the LLM decides to stop\n",
    "- This is how all autonomous agents work under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concept 4: Checkpointing - Time Travel for Agents\n",
    "\n",
    "This is LangGraph's superpower for legal AI. Imagine you could save/load your game state at any point.\n",
    "\n",
    "**Use Cases**:\n",
    "- Pause agent for lawyer approval\n",
    "- Resume from where you left off\n",
    "- Debug by rewinding state\n",
    "- A/B test different paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXECUTION 1: Running until interrupt...\n",
      "============================================================\n",
      "ðŸ“„ Analyzing contract...\n",
      "   Risk Level: HIGH\n",
      "\n",
      "State after pause: {'contract_text': 'Party A shall indemnify Party B...', 'risk_level': 'HIGH', 'requires_review': True, 'approved': False}\n",
      "\n",
      "(Lawyer reviews and approves...)\n",
      "\n",
      "============================================================\n",
      "EXECUTION 2: Resuming from checkpoint...\n",
      "============================================================\n",
      "â¸ï¸  PAUSED: Waiting for lawyer approval...\n",
      "âœ… Contract finalized!\n",
      "\n",
      "Final state: {'contract_text': 'Party A shall indemnify Party B...', 'risk_level': 'HIGH', 'requires_review': True, 'approved': True}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "class ContractState(TypedDict):\n",
    "    contract_text: str\n",
    "    risk_level: str\n",
    "    requires_review: bool\n",
    "    approved: bool\n",
    "\n",
    "def analyze_contract(state: ContractState) -> dict:\n",
    "    print(\"ðŸ“„ Analyzing contract...\")\n",
    "    # Simulate risk analysis\n",
    "    risk = \"HIGH\" if \"indemnify\" in state[\"contract_text\"].lower() else \"LOW\"\n",
    "    requires_review = risk == \"HIGH\"\n",
    "    \n",
    "    print(f\"   Risk Level: {risk}\")\n",
    "    return {\n",
    "        \"risk_level\": risk,\n",
    "        \"requires_review\": requires_review\n",
    "    }\n",
    "\n",
    "def await_approval(state: ContractState) -> dict:\n",
    "    print(\"â¸ï¸  PAUSED: Waiting for lawyer approval...\")\n",
    "    # This is where execution stops!\n",
    "    return {}\n",
    "\n",
    "def finalize_contract(state: ContractState) -> dict:\n",
    "    print(\"âœ… Contract finalized!\")\n",
    "    return {\"approved\": True}\n",
    "\n",
    "def should_pause_for_review(state: ContractState) -> Literal[\"await_approval\", \"finalize\"]:\n",
    "    if state[\"requires_review\"]:\n",
    "        return \"await_approval\"\n",
    "    return \"finalize\"\n",
    "\n",
    "# Build graph with checkpointing\n",
    "graph = StateGraph(ContractState)\n",
    "graph.add_node(\"analyze\", analyze_contract)\n",
    "graph.add_node(\"await_approval\", await_approval)\n",
    "graph.add_node(\"finalize\", finalize_contract)\n",
    "\n",
    "graph.add_edge(START, \"analyze\")\n",
    "graph.add_conditional_edges(\n",
    "    \"analyze\",\n",
    "    should_pause_for_review,\n",
    "    {\n",
    "        \"await_approval\": \"await_approval\",\n",
    "        \"finalize\": \"finalize\"\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"await_approval\", \"finalize\")\n",
    "graph.add_edge(\"finalize\", END)\n",
    "\n",
    "# Add checkpointing (this enables pause/resume)\n",
    "checkpointer = MemorySaver()\n",
    "app = graph.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    interrupt_before=[\"await_approval\"]  # Pause before this node\n",
    ")\n",
    "\n",
    "# Test with high-risk contract\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"contract_123\"}}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXECUTION 1: Running until interrupt...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = app.invoke(\n",
    "    {\n",
    "        \"contract_text\": \"Party A shall indemnify Party B...\",\n",
    "        \"risk_level\": \"\",\n",
    "        \"requires_review\": False,\n",
    "        \"approved\": False\n",
    "    },\n",
    "    config=thread_config\n",
    ")\n",
    "\n",
    "print(f\"\\nState after pause: {result}\")\n",
    "print(\"\\n(Lawyer reviews and approves...)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXECUTION 2: Resuming from checkpoint...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Resume from checkpoint (same thread_id)\n",
    "result = app.invoke(None, config=thread_config)\n",
    "\n",
    "print(f\"\\nFinal state: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insights**:\n",
    "- `interrupt_before` pauses execution before a node\n",
    "- `thread_id` identifies a unique execution instance\n",
    "- Resume by invoking with `None` and same thread_id\n",
    "- Critical for legal workflows: human-in-the-loop approval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concept 5: Subgraphs - Your Manager-Worker Pattern\n",
    "\n",
    "You built orchestrators that managed sub-agents. LangGraph makes this first-class with **subgraphs**.\n",
    "\n",
    "Example: Contract review with specialized analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MANAGER-WORKER PATTERN EXECUTION\n",
      "============================================================\n",
      "\n",
      "ðŸ“‹ Manager: Extracting clauses...\n",
      "\n",
      "ðŸ¤– Manager: Delegating to clause analyzers...\n",
      "\n",
      "  Analyzing clause 1/3\n",
      "   ðŸ” Identifying clause type: Party A shall indemnify Party B against all claims...\n",
      "   ðŸ“Š Assessing risk for LIABILITY clause\n",
      "     Result: LIABILITY (Risk: 8/10)\n",
      "\n",
      "  Analyzing clause 2/3\n",
      "   ðŸ” Identifying clause type: Payment terms: Net 30 days from invoice date....\n",
      "   ðŸ“Š Assessing risk for PAYMENT clause\n",
      "     Result: PAYMENT (Risk: 3/10)\n",
      "\n",
      "  Analyzing clause 3/3\n",
      "   ðŸ” Identifying clause type: This agreement is governed by the laws of Californ...\n",
      "   ðŸ“Š Assessing risk for GENERAL clause\n",
      "     Result: GENERAL (Risk: 3/10)\n",
      "\n",
      "ðŸ“Š Manager: Determining overall risk...\n",
      "   Average risk score: 4.7/10\n",
      "   Overall risk: MEDIUM\n",
      "\n",
      "============================================================\n",
      "FINAL RESULT\n",
      "============================================================\n",
      "Overall Risk: MEDIUM\n",
      "Analyzed 3 clauses\n"
     ]
    }
   ],
   "source": [
    "# Worker subgraph: Clause analyzer\n",
    "class ClauseState(TypedDict):\n",
    "    clause_text: str\n",
    "    clause_type: str\n",
    "    risk_score: int\n",
    "\n",
    "def identify_clause_type(state: ClauseState) -> dict:\n",
    "    print(f\"   ðŸ” Identifying clause type: {state['clause_text'][:50]}...\")\n",
    "    \n",
    "    # Simple heuristic\n",
    "    text = state[\"clause_text\"].lower()\n",
    "    if \"liability\" in text or \"indemnif\" in text:\n",
    "        clause_type = \"LIABILITY\"\n",
    "    elif \"payment\" in text or \"fee\" in text:\n",
    "        clause_type = \"PAYMENT\"\n",
    "    else:\n",
    "        clause_type = \"GENERAL\"\n",
    "    \n",
    "    return {\"clause_type\": clause_type}\n",
    "\n",
    "def assess_risk(state: ClauseState) -> dict:\n",
    "    print(f\"   ðŸ“Š Assessing risk for {state['clause_type']} clause\")\n",
    "    \n",
    "    risk_score = 8 if state[\"clause_type\"] == \"LIABILITY\" else 3\n",
    "    return {\"risk_score\": risk_score}\n",
    "\n",
    "# Build worker subgraph\n",
    "clause_graph = StateGraph(ClauseState)\n",
    "clause_graph.add_node(\"identify\", identify_clause_type)\n",
    "clause_graph.add_node(\"assess\", assess_risk)\n",
    "clause_graph.add_edge(START, \"identify\")\n",
    "clause_graph.add_edge(\"identify\", \"assess\")\n",
    "clause_graph.add_edge(\"assess\", END)\n",
    "\n",
    "clause_analyzer = clause_graph.compile()\n",
    "\n",
    "# Manager graph: Orchestrates multiple clause analyses\n",
    "class ContractManagerState(TypedDict):\n",
    "    clauses: list[str]\n",
    "    analysis_results: list[dict]\n",
    "    overall_risk: str\n",
    "\n",
    "def extract_clauses(state: ContractManagerState) -> dict:\n",
    "    print(\"\\nðŸ“‹ Manager: Extracting clauses...\")\n",
    "    # Simulate clause extraction\n",
    "    clauses = [\n",
    "        \"Party A shall indemnify Party B against all claims.\",\n",
    "        \"Payment terms: Net 30 days from invoice date.\",\n",
    "        \"This agreement is governed by the laws of California.\"\n",
    "    ]\n",
    "    return {\"clauses\": clauses}\n",
    "\n",
    "def analyze_all_clauses(state: ContractManagerState) -> dict:\n",
    "    print(\"\\nðŸ¤– Manager: Delegating to clause analyzers...\")\n",
    "    \n",
    "    results = []\n",
    "    for i, clause in enumerate(state[\"clauses\"], 1):\n",
    "        print(f\"\\n  Analyzing clause {i}/{len(state['clauses'])}\")\n",
    "        \n",
    "        # Invoke the subgraph (worker)\n",
    "        analysis = clause_analyzer.invoke({\n",
    "            \"clause_text\": clause,\n",
    "            \"clause_type\": \"\",\n",
    "            \"risk_score\": 0\n",
    "        })\n",
    "        \n",
    "        results.append(analysis)\n",
    "        print(f\"     Result: {analysis['clause_type']} (Risk: {analysis['risk_score']}/10)\")\n",
    "    \n",
    "    return {\"analysis_results\": results}\n",
    "\n",
    "def determine_overall_risk(state: ContractManagerState) -> dict:\n",
    "    print(\"\\nðŸ“Š Manager: Determining overall risk...\")\n",
    "    \n",
    "    avg_risk = sum(r[\"risk_score\"] for r in state[\"analysis_results\"]) / len(state[\"analysis_results\"])\n",
    "    overall = \"HIGH\" if avg_risk > 6 else \"MEDIUM\" if avg_risk > 3 else \"LOW\"\n",
    "    \n",
    "    print(f\"   Average risk score: {avg_risk:.1f}/10\")\n",
    "    print(f\"   Overall risk: {overall}\")\n",
    "    \n",
    "    return {\"overall_risk\": overall}\n",
    "\n",
    "# Build manager graph\n",
    "manager_graph = StateGraph(ContractManagerState)\n",
    "manager_graph.add_node(\"extract\", extract_clauses)\n",
    "manager_graph.add_node(\"analyze\", analyze_all_clauses)\n",
    "manager_graph.add_node(\"aggregate\", determine_overall_risk)\n",
    "\n",
    "manager_graph.add_edge(START, \"extract\")\n",
    "manager_graph.add_edge(\"extract\", \"analyze\")\n",
    "manager_graph.add_edge(\"analyze\", \"aggregate\")\n",
    "manager_graph.add_edge(\"aggregate\", END)\n",
    "\n",
    "manager_app = manager_graph.compile()\n",
    "\n",
    "# Run the manager\n",
    "print(\"=\"*60)\n",
    "print(\"MANAGER-WORKER PATTERN EXECUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = manager_app.invoke({\n",
    "    \"clauses\": [],\n",
    "    \"analysis_results\": [],\n",
    "    \"overall_risk\": \"\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Overall Risk: {result['overall_risk']}\")\n",
    "print(f\"Analyzed {len(result['analysis_results'])} clauses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insights**:\n",
    "- Subgraphs are just compiled graphs used as nodes\n",
    "- Manager invokes worker subgraphs via `.invoke()`\n",
    "- Each subgraph has its own state schema\n",
    "- This is how you build modular, scalable agent systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concept 6: Parallel Execution - Your Multi-Agent Pattern\n",
    "\n",
    "You ran multiple agents in parallel. LangGraph supports this with `Send()` API for dynamic fan-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PARALLEL EXECUTION DEMO\n",
      "============================================================\n",
      "ðŸ“„ Splitting contract into sections...\n",
      "\n",
      "ðŸš€ Launching 5 parallel analyses...\n",
      "\n",
      "   Worker 0: Analyzing 'Definitions and Interpretations'...\n",
      "   Worker 1: Analyzing 'Scope of Services'...\n",
      "   Worker 2: Analyzing 'Payment Terms'...\n",
      "   Worker 3: Analyzing 'Liability and Indemnification'...\n",
      "   Worker 4: Analyzing 'Termination Clause'...\n",
      "   Worker 0: âœ… Complete\n",
      "   Worker 1: âœ… Complete\n",
      "   Worker 4: âœ… Complete\n",
      "   Worker 3: âœ… Complete\n",
      "   Worker 2: âœ… Complete\n"
     ]
    },
    {
     "ename": "InvalidUpdateError",
     "evalue": "At key 'analysis': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidUpdateError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     71\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m result = \u001b[43mparallel_app\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontract_sections\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manalyses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m elapsed = time.time() - start_time\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâ±ï¸  Completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms (would be ~2.5s if sequential)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\langgraph\\pregel\\main.py:2689\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2679\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.tick(\n\u001b[32m   2680\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2681\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2684\u001b[39m ):\n\u001b[32m   2685\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2686\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[32m   2687\u001b[39m         stream_mode, print_mode, subgraphs, stream.get, queue.Empty\n\u001b[32m   2688\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2689\u001b[39m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_tick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2690\u001b[39m \u001b[38;5;66;03m# wait for checkpoint\u001b[39;00m\n\u001b[32m   2691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m durability_ == \u001b[33m\"\u001b[39m\u001b[33msync\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\langgraph\\pregel\\_loop.py:523\u001b[39m, in \u001b[36mPregelLoop.after_tick\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    521\u001b[39m writes = [w \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tasks.values() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m t.writes]\n\u001b[32m    522\u001b[39m \u001b[38;5;66;03m# all tasks have finished\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[43mapply_writes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpointer_get_next_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[38;5;66;03m# produce values output\u001b[39;00m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.updated_channels.isdisjoint(\n\u001b[32m    532\u001b[39m     (\u001b[38;5;28mself\u001b[39m.output_keys,)\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.output_keys, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_keys\n\u001b[32m    535\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\langgraph\\pregel\\_algo.py:293\u001b[39m, in \u001b[36mapply_writes\u001b[39m\u001b[34m(checkpoint, channels, tasks, get_next_version, trigger_to_nodes)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chan, vals \u001b[38;5;129;01min\u001b[39;00m pending_writes_by_channel.items():\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    294\u001b[39m             checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m][chan] = next_version\n\u001b[32m    295\u001b[39m             \u001b[38;5;66;03m# unavailable channels can't trigger tasks, so don't add them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\langgraph\\channels\\last_value.py:64\u001b[39m, in \u001b[36mLastValue.update\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) != \u001b[32m1\u001b[39m:\n\u001b[32m     60\u001b[39m     msg = create_error_message(\n\u001b[32m     61\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAt key \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: Can receive only one value per step. Use an Annotated key to handle multiple values.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     62\u001b[39m         error_code=ErrorCode.INVALID_CONCURRENT_GRAPH_UPDATE,\n\u001b[32m     63\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m.value = values[-\u001b[32m1\u001b[39m]\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mInvalidUpdateError\u001b[39m: At key 'analysis': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Send\n",
    "import time\n",
    "\n",
    "class ParallelState(TypedDict):\n",
    "    contract_sections: list[str]\n",
    "    analyses: list[dict]\n",
    "\n",
    "class SectionState(TypedDict):\n",
    "    section: str\n",
    "    section_id: int\n",
    "    analysis: str\n",
    "\n",
    "def split_contract(state: ParallelState) -> dict:\n",
    "    print(\"ðŸ“„ Splitting contract into sections...\")\n",
    "    sections = [\n",
    "        \"Definitions and Interpretations\",\n",
    "        \"Scope of Services\",\n",
    "        \"Payment Terms\",\n",
    "        \"Liability and Indemnification\",\n",
    "        \"Termination Clause\"\n",
    "    ]\n",
    "    return {\"contract_sections\": sections}\n",
    "\n",
    "# This is the magic: fan out to parallel workers\n",
    "def start_parallel_analysis(state: ParallelState):\n",
    "    print(f\"\\nðŸš€ Launching {len(state['contract_sections'])} parallel analyses...\\n\")\n",
    "    \n",
    "    # Send() creates a message to a specific node for each section\n",
    "    return [\n",
    "        Send(\n",
    "            \"analyze_section\",\n",
    "            {\"section\": section, \"section_id\": i, \"analysis\": \"\"}\n",
    "        )\n",
    "        for i, section in enumerate(state[\"contract_sections\"])\n",
    "    ]\n",
    "\n",
    "def analyze_section(state: SectionState) -> dict:\n",
    "    \"\"\"This runs in parallel for each section\"\"\"\n",
    "    print(f\"   Worker {state['section_id']}: Analyzing '{state['section']}'...\")\n",
    "    time.sleep(0.5)  # Simulate work\n",
    "    \n",
    "    analysis = f\"Section '{state['section']}' reviewed. Risk: MEDIUM\"\n",
    "    print(f\"   Worker {state['section_id']}: âœ… Complete\")\n",
    "    \n",
    "    return {\"analysis\": analysis}\n",
    "\n",
    "def aggregate_results(state: ParallelState) -> dict:\n",
    "    print(\"\\nðŸ“Š Aggregating parallel results...\")\n",
    "    # All parallel analyses are now complete\n",
    "    return {}\n",
    "\n",
    "# Build parallel graph\n",
    "parallel_graph = StateGraph(ParallelState)\n",
    "parallel_graph.add_node(\"split\", split_contract)\n",
    "parallel_graph.add_node(\"analyze_section\", analyze_section)\n",
    "parallel_graph.add_node(\"aggregate\", aggregate_results)\n",
    "\n",
    "parallel_graph.add_edge(START, \"split\")\n",
    "# Conditional edge returns a list of Send() objects\n",
    "parallel_graph.add_conditional_edges(\"split\", start_parallel_analysis)\n",
    "parallel_graph.add_edge(\"analyze_section\", \"aggregate\")\n",
    "parallel_graph.add_edge(\"aggregate\", END)\n",
    "\n",
    "parallel_app = parallel_graph.compile()\n",
    "\n",
    "# Run it\n",
    "print(\"=\"*60)\n",
    "print(\"PARALLEL EXECUTION DEMO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "result = parallel_app.invoke({\n",
    "    \"contract_sections\": [],\n",
    "    \"analyses\": []\n",
    "})\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâ±ï¸  Completed in {elapsed:.2f}s (would be ~2.5s if sequential)\")\n",
    "print(f\"Analyzed {len(result['contract_sections'])} sections in parallel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insights**:\n",
    "- `Send(node_name, input_state)` creates a parallel execution path\n",
    "- Return list of `Send()` from conditional edges for fan-out\n",
    "- LangGraph automatically waits for all parallel nodes before continuing\n",
    "- This is how you scale agent systems for large documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concept 7: Streaming - Real-Time Updates\n",
    "\n",
    "LangGraph can stream state updates as the graph executes. Critical for UX when agents take time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STREAMING EXECUTION\n",
      "============================================================\n",
      "\n",
      "ðŸ“¡ Update: {'step1': {'progress': 'Extracting clauses', 'step': 1}}\n",
      "\n",
      "ðŸ“¡ Update: {'step2': {'progress': 'Analyzing risks', 'step': 2}}\n",
      "\n",
      "ðŸ“¡ Update: {'step3': {'progress': 'Generating report', 'step': 3}}\n",
      "\n",
      "âœ… Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "class StreamState(TypedDict):\n",
    "    progress: str\n",
    "    step: int\n",
    "\n",
    "def step1(state: StreamState) -> dict:\n",
    "    time.sleep(1)\n",
    "    return {\"progress\": \"Extracting clauses\", \"step\": 1}\n",
    "\n",
    "def step2(state: StreamState) -> dict:\n",
    "    time.sleep(1)\n",
    "    return {\"progress\": \"Analyzing risks\", \"step\": 2}\n",
    "\n",
    "def step3(state: StreamState) -> dict:\n",
    "    time.sleep(1)\n",
    "    return {\"progress\": \"Generating report\", \"step\": 3}\n",
    "\n",
    "# Build graph\n",
    "stream_graph = StateGraph(StreamState)\n",
    "stream_graph.add_node(\"step1\", step1)\n",
    "stream_graph.add_node(\"step2\", step2)\n",
    "stream_graph.add_node(\"step3\", step3)\n",
    "\n",
    "stream_graph.add_edge(START, \"step1\")\n",
    "stream_graph.add_edge(\"step1\", \"step2\")\n",
    "stream_graph.add_edge(\"step2\", \"step3\")\n",
    "stream_graph.add_edge(\"step3\", END)\n",
    "\n",
    "stream_app = stream_graph.compile()\n",
    "\n",
    "# Stream the execution\n",
    "print(\"=\"*60)\n",
    "print(\"STREAMING EXECUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for chunk in stream_app.stream({\"progress\": \"Starting\", \"step\": 0}):\n",
    "    print(f\"\\nðŸ“¡ Update: {chunk}\")\n",
    "\n",
    "print(\"\\nâœ… Streaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insights**:\n",
    "- Use `.stream()` instead of `.invoke()` for real-time updates\n",
    "- Each node completion emits a chunk\n",
    "- Critical for user feedback on long-running agents\n",
    "- LegalOn likely streams contract analysis progress to lawyers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concept 8: Putting It All Together - Legal Contract Reviewer\n",
    "\n",
    "Let's build a mini version of what LegalOn might use:\n",
    "1. Upload contract\n",
    "2. Parallel analysis of sections\n",
    "3. Risk scoring\n",
    "4. Human review checkpoint\n",
    "5. Final report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LEGAL CONTRACT REVIEW SYSTEM - FULL DEMO\n",
      "============================================================\n",
      "\n",
      "ðŸ“„ Parsing contract into sections...\n",
      "   Found 5 sections\n",
      "\n",
      "ðŸš€ Routing sections to parallel analyzers...\n",
      "   ðŸ” Worker 0: Analyzing section...\n",
      "   ðŸ” Worker 0: Risk=LOW, Issues=0\n",
      "   ðŸ” Worker 3: Analyzing section...\n",
      "   ðŸ” Worker 3: Risk=CRITICAL, Issues=2\n",
      "   ðŸ” Worker 1: Analyzing section...\n",
      "   ðŸ” Worker 1: Risk=LOW, Issues=0\n",
      "   ðŸ” Worker 2: Analyzing section...\n",
      "   ðŸ” Worker 2: Risk=LOW, Issues=0\n",
      "   ðŸ” Worker 4: Analyzing section...\n",
      "   ðŸ” Worker 4: Risk=MEDIUM, Issues=1\n"
     ]
    },
    {
     "ename": "InvalidUpdateError",
     "evalue": "At key 'risk_level': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidUpdateError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 176\u001b[39m\n\u001b[32m    173\u001b[39m thread_config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcontract_789\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# Phase 1: Run until lawyer checkpoint\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m result = \u001b[43mlegal_app\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontract_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSample contract...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msections\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msection_analyses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moverall_risk\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrequires_lawyer_review\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlawyer_approved\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfinal_report\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthread_config\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m    190\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m(Lawyer reviews and approves the contract...)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\langgraph\\pregel\\main.py:2689\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2679\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.tick(\n\u001b[32m   2680\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2681\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2684\u001b[39m ):\n\u001b[32m   2685\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2686\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[32m   2687\u001b[39m         stream_mode, print_mode, subgraphs, stream.get, queue.Empty\n\u001b[32m   2688\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2689\u001b[39m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_tick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2690\u001b[39m \u001b[38;5;66;03m# wait for checkpoint\u001b[39;00m\n\u001b[32m   2691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m durability_ == \u001b[33m\"\u001b[39m\u001b[33msync\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\langgraph\\pregel\\_loop.py:523\u001b[39m, in \u001b[36mPregelLoop.after_tick\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    521\u001b[39m writes = [w \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tasks.values() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m t.writes]\n\u001b[32m    522\u001b[39m \u001b[38;5;66;03m# all tasks have finished\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[43mapply_writes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpointer_get_next_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[38;5;66;03m# produce values output\u001b[39;00m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.updated_channels.isdisjoint(\n\u001b[32m    532\u001b[39m     (\u001b[38;5;28mself\u001b[39m.output_keys,)\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.output_keys, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_keys\n\u001b[32m    535\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\langgraph\\pregel\\_algo.py:293\u001b[39m, in \u001b[36mapply_writes\u001b[39m\u001b[34m(checkpoint, channels, tasks, get_next_version, trigger_to_nodes)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chan, vals \u001b[38;5;129;01min\u001b[39;00m pending_writes_by_channel.items():\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    294\u001b[39m             checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m][chan] = next_version\n\u001b[32m    295\u001b[39m             \u001b[38;5;66;03m# unavailable channels can't trigger tasks, so don't add them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\langgraph\\channels\\last_value.py:64\u001b[39m, in \u001b[36mLastValue.update\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) != \u001b[32m1\u001b[39m:\n\u001b[32m     60\u001b[39m     msg = create_error_message(\n\u001b[32m     61\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAt key \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: Can receive only one value per step. Use an Annotated key to handle multiple values.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     62\u001b[39m         error_code=ErrorCode.INVALID_CONCURRENT_GRAPH_UPDATE,\n\u001b[32m     63\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m.value = values[-\u001b[32m1\u001b[39m]\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mInvalidUpdateError\u001b[39m: At key 'risk_level': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from operator import add\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Send\n",
    "\n",
    "# Main contract state\n",
    "class LegalReviewState(TypedDict):\n",
    "    contract_text: str\n",
    "    sections: list[str]\n",
    "    section_analyses: Annotated[list[dict], add]  # Append results\n",
    "    overall_risk: str\n",
    "    requires_lawyer_review: bool\n",
    "    lawyer_approved: bool\n",
    "    final_report: str\n",
    "\n",
    "# Section analysis state (for parallel workers)\n",
    "class SectionAnalysisState(TypedDict):\n",
    "    section_text: str\n",
    "    section_id: int\n",
    "    risk_level: str\n",
    "    issues: list[str]\n",
    "\n",
    "# Node 1: Parse contract into sections\n",
    "def parse_contract(state: LegalReviewState) -> dict:\n",
    "    print(\"\\nðŸ“„ Parsing contract into sections...\")\n",
    "    \n",
    "    # Simulate section extraction\n",
    "    sections = [\n",
    "        \"DEFINITIONS: Party A (Provider), Party B (Client)...\",\n",
    "        \"SCOPE: Provider shall deliver services as outlined...\",\n",
    "        \"PAYMENT: Client agrees to pay $10,000 per month...\",\n",
    "        \"LIABILITY: Provider shall indemnify Client against ALL claims...\",\n",
    "        \"TERMINATION: Either party may terminate with 30 days notice...\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"   Found {len(sections)} sections\")\n",
    "    return {\"sections\": sections}\n",
    "\n",
    "# Node 2: Fan out to parallel section analyzers\n",
    "def route_to_analyzers(state: LegalReviewState):\n",
    "    print(\"\\nðŸš€ Routing sections to parallel analyzers...\")\n",
    "    return [\n",
    "        Send(\n",
    "            \"analyze_section_worker\",\n",
    "            {\n",
    "                \"section_text\": section,\n",
    "                \"section_id\": i,\n",
    "                \"risk_level\": \"\",\n",
    "                \"issues\": []\n",
    "            }\n",
    "        )\n",
    "        for i, section in enumerate(state[\"sections\"])\n",
    "    ]\n",
    "\n",
    "# Worker: Analyze individual section\n",
    "def analyze_section_worker(state: SectionAnalysisState) -> dict:\n",
    "    print(f\"   ðŸ” Worker {state['section_id']}: Analyzing section...\")\n",
    "    \n",
    "    # Simulate risk analysis\n",
    "    text = state[\"section_text\"].lower()\n",
    "    \n",
    "    if \"indemnify\" in text and \"all\" in text:\n",
    "        risk = \"CRITICAL\"\n",
    "        issues = [\"Unlimited indemnification clause\", \"No cap on liability\"]\n",
    "    elif \"termination\" in text:\n",
    "        risk = \"MEDIUM\"\n",
    "        issues = [\"Short notice period\"]\n",
    "    else:\n",
    "        risk = \"LOW\"\n",
    "        issues = []\n",
    "    \n",
    "    print(f\"   ðŸ” Worker {state['section_id']}: Risk={risk}, Issues={len(issues)}\")\n",
    "    \n",
    "    return {\n",
    "        \"risk_level\": risk,\n",
    "        \"issues\": issues,\n",
    "        \"section_analyses\": [{\n",
    "            \"section_id\": state[\"section_id\"],\n",
    "            \"risk\": risk,\n",
    "            \"issues\": issues\n",
    "        }]\n",
    "    }\n",
    "\n",
    "# Node 3: Aggregate parallel results\n",
    "def aggregate_risks(state: LegalReviewState) -> dict:\n",
    "    print(\"\\nðŸ“Š Aggregating risk analysis...\")\n",
    "    \n",
    "    risk_levels = [a[\"risk\"] for a in state[\"section_analyses\"]]\n",
    "    has_critical = \"CRITICAL\" in risk_levels\n",
    "    \n",
    "    overall_risk = \"HIGH\" if has_critical else \"MEDIUM\" if \"MEDIUM\" in risk_levels else \"LOW\"\n",
    "    requires_review = has_critical\n",
    "    \n",
    "    print(f\"   Overall Risk: {overall_risk}\")\n",
    "    print(f\"   Requires Lawyer Review: {requires_review}\")\n",
    "    \n",
    "    return {\n",
    "        \"overall_risk\": overall_risk,\n",
    "        \"requires_lawyer_review\": requires_review\n",
    "    }\n",
    "\n",
    "# Node 4: Human review checkpoint\n",
    "def await_lawyer_approval(state: LegalReviewState) -> dict:\n",
    "    print(\"\\nâš–ï¸  CHECKPOINT: Awaiting lawyer approval...\")\n",
    "    print(\"   (In production, this would notify the legal team)\")\n",
    "    return {}\n",
    "\n",
    "# Node 5: Generate final report\n",
    "def generate_report(state: LegalReviewState) -> dict:\n",
    "    print(\"\\nðŸ“ Generating final report...\")\n",
    "    \n",
    "    report = f\"\"\"\\n\n",
    "    CONTRACT REVIEW REPORT\n",
    "    =====================\n",
    "    \n",
    "    Overall Risk Level: {state['overall_risk']}\n",
    "    Sections Analyzed: {len(state['section_analyses'])}\n",
    "    \n",
    "    CRITICAL ISSUES:\n",
    "    \"\"\"\n",
    "    \n",
    "    for analysis in state[\"section_analyses\"]:\n",
    "        if analysis[\"risk\"] == \"CRITICAL\":\n",
    "            report += f\"\\n    - Section {analysis['section_id']}: {', '.join(analysis['issues'])}\"\n",
    "    \n",
    "    report += \"\\n\\n    Lawyer Approved: \" + (\"âœ… YES\" if state.get(\"lawyer_approved\") else \"â³ PENDING\")\n",
    "    \n",
    "    print(report)\n",
    "    return {\"final_report\": report}\n",
    "\n",
    "# Router: Should we pause for lawyer?\n",
    "def check_review_needed(state: LegalReviewState) -> Literal[\"await_approval\", \"generate_report\"]:\n",
    "    if state[\"requires_lawyer_review\"]:\n",
    "        return \"await_approval\"\n",
    "    return \"generate_report\"\n",
    "\n",
    "# Build the full legal review graph\n",
    "legal_graph = StateGraph(LegalReviewState)\n",
    "\n",
    "legal_graph.add_node(\"parse\", parse_contract)\n",
    "legal_graph.add_node(\"analyze_section_worker\", analyze_section_worker)\n",
    "legal_graph.add_node(\"aggregate\", aggregate_risks)\n",
    "legal_graph.add_node(\"await_approval\", await_lawyer_approval)\n",
    "legal_graph.add_node(\"generate_report\", generate_report)\n",
    "\n",
    "# Build the flow\n",
    "legal_graph.add_edge(START, \"parse\")\n",
    "legal_graph.add_conditional_edges(\"parse\", route_to_analyzers)\n",
    "legal_graph.add_edge(\"analyze_section_worker\", \"aggregate\")\n",
    "legal_graph.add_conditional_edges(\n",
    "    \"aggregate\",\n",
    "    check_review_needed,\n",
    "    {\n",
    "        \"await_approval\": \"await_approval\",\n",
    "        \"generate_report\": \"generate_report\"\n",
    "    }\n",
    ")\n",
    "legal_graph.add_edge(\"await_approval\", \"generate_report\")\n",
    "legal_graph.add_edge(\"generate_report\", END)\n",
    "\n",
    "# Compile with checkpointing\n",
    "checkpointer = MemorySaver()\n",
    "legal_app = legal_graph.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    interrupt_before=[\"await_approval\"]\n",
    ")\n",
    "\n",
    "# Execute the full pipeline\n",
    "print(\"=\"*60)\n",
    "print(\"LEGAL CONTRACT REVIEW SYSTEM - FULL DEMO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"contract_789\"}}\n",
    "\n",
    "# Phase 1: Run until lawyer checkpoint\n",
    "result = legal_app.invoke(\n",
    "    {\n",
    "        \"contract_text\": \"Sample contract...\",\n",
    "        \"sections\": [],\n",
    "        \"section_analyses\": [],\n",
    "        \"overall_risk\": \"\",\n",
    "        \"requires_lawyer_review\": False,\n",
    "        \"lawyer_approved\": False,\n",
    "        \"final_report\": \"\"\n",
    "    },\n",
    "    config=thread_config\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"(Lawyer reviews and approves the contract...)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Simulate lawyer approval\n",
    "import time\n",
    "time.sleep(2)\n",
    "\n",
    "# Phase 2: Resume from checkpoint\n",
    "result = legal_app.invoke(None, config=thread_config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… PIPELINE COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Prep Summary\n",
    "\n",
    "### Key Talking Points\n",
    "\n",
    "1. **StateGraph = Your Game State Machines**\n",
    "   - TypedDict for type safety\n",
    "   - Nodes modify state, edges define flow\n",
    "   - Like animation state machines but for agent logic\n",
    "\n",
    "2. **Conditional Edges = Dynamic Routing**\n",
    "   - Functions that inspect state and decide next node\n",
    "   - Enable loops (self-edges) for agent iterations\n",
    "   - The core of ReAct pattern\n",
    "\n",
    "3. **Checkpointing = Time Travel**\n",
    "   - Human-in-the-loop approval (critical for legal)\n",
    "   - Pause/resume execution\n",
    "   - Debug and A/B test different paths\n",
    "\n",
    "4. **Subgraphs = Your Manager-Worker Pattern**\n",
    "   - Compiled graphs used as nodes\n",
    "   - Modular, reusable agent components\n",
    "   - Manager orchestrates specialized workers\n",
    "\n",
    "5. **Parallelization = Scale**\n",
    "   - `Send()` API for dynamic fan-out\n",
    "   - Analyze multiple contract sections simultaneously\n",
    "   - Automatic synchronization\n",
    "\n",
    "6. **Streaming = UX**\n",
    "   - Real-time progress updates\n",
    "   - Critical for long-running legal analysis\n",
    "   - Better user experience for lawyers\n",
    "\n",
    "### What They're Looking For\n",
    "\n",
    "**Technical Skills:**\n",
    "- Understanding of stateful agent architectures\n",
    "- Experience with orchestration patterns\n",
    "- Knowledge of LLM agent frameworks\n",
    "\n",
    "**Legal Domain:**\n",
    "- Human-in-the-loop workflows\n",
    "- Risk assessment pipelines\n",
    "- Document processing at scale\n",
    "\n",
    "**Your Strengths to Highlight:**\n",
    "- Game dev state machine expertise â†’ LangGraph state graphs\n",
    "- Claude Code orchestrator experience â†’ Manager-worker pattern\n",
    "- Multi-agent parallel execution â†’ Send() API\n",
    "\n",
    "### Questions to Ask Them\n",
    "\n",
    "1. \"How do you handle version control for agent prompts across your Legal Document Graph?\"\n",
    "2. \"What's your strategy for evaluating agent performance on legal accuracy?\"\n",
    "3. \"How do you integrate human lawyer feedback back into the training loop?\"\n",
    "4. \"What's the most challenging aspect of the OpenAI partnership integration?\"\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Before Tuesday:\n",
    "1. âœ… Run all cells in this notebook\n",
    "2. ðŸ“š Read LangGraph docs on:\n",
    "   - [ReAct Agent](https://langchain-ai.github.io/langgraph/tutorials/introduction/)\n",
    "   - [Human-in-the-loop](https://langchain-ai.github.io/langgraph/how-tos/human-in-the-loop/)\n",
    "   - [Subgraphs](https://langchain-ai.github.io/langgraph/how-tos/subgraph/)\n",
    "3. ðŸ”§ Build a mini contract analyzer with real Claude calls\n",
    "4. ðŸ’ª Practice explaining patterns using your game dev analogies\n",
    "\n",
    "**You've got this! Your orchestrator experience maps perfectly to LangGraph.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
